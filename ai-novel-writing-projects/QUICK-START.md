# å¿«é€Ÿå¼€å§‹æŒ‡å— / Quick Start Guide

## ğŸš€ 5åˆ†é’Ÿå¼€å§‹AIå°è¯´åˆ›ä½œ

### ç¬¬ä¸€æ­¥ï¼šé€‰æ‹©å·¥å…·

#### åœºæ™¯Aï¼šæˆ‘æƒ³å¿«é€Ÿä½“éªŒï¼ˆäº‘ç«¯æ–¹æ¡ˆï¼‰
æ¨èä½¿ç”¨åœ¨çº¿å·¥å…·ï¼Œæ— éœ€å®‰è£…ï¼š
- **ä¸­æ–‡**: 302_novel_writing
- **è‹±æ–‡**: GPTAuthor æˆ– NovelAI

**ä¼˜ç‚¹**: å³å¼€å³ç”¨ï¼Œæ— éœ€æŠ€æœ¯èƒŒæ™¯
**ç¼ºç‚¹**: éœ€è¦APIå¯†é’¥ï¼Œæœ‰ä½¿ç”¨æˆæœ¬

#### åœºæ™¯Bï¼šæˆ‘æ³¨é‡éšç§ï¼ˆæœ¬åœ°æ–¹æ¡ˆï¼‰
æ¨èæœ¬åœ°éƒ¨ç½²ï¼š
- **å·¥å…·**: AIStoryWriter + Ollama
- **æ¨¡å‹**: Llama 3, Mistral

**ä¼˜ç‚¹**: å®Œå…¨ç§å¯†ï¼Œæ— ä½¿ç”¨é™åˆ¶
**ç¼ºç‚¹**: éœ€è¦GPUï¼ŒæŠ€æœ¯é—¨æ§›è¾ƒé«˜

#### åœºæ™¯Cï¼šæˆ‘æƒ³äººæœºååŒï¼ˆæ··åˆæ–¹æ¡ˆï¼‰
æ¨èåŠè‡ªåŠ¨å·¥å…·ï¼š
- **GPTAuthor**: äººå·¥å®¡æ ¸+AIç”Ÿæˆ
- **WriterAI**: AIè¾…åŠ©äººç±»åˆ›ä½œ

**ä¼˜ç‚¹**: å¹³è¡¡æ§åˆ¶å’Œæ•ˆç‡
**ç¼ºç‚¹**: éœ€è¦æ—¶é—´æŠ•å…¥

---

## ğŸ“‹ ç¯å¢ƒå‡†å¤‡

### æ–¹æ¡ˆ1ï¼šä½¿ç”¨äº‘ç«¯API

#### 1. è·å–APIå¯†é’¥

**OpenAI**:
```bash
# è®¿é—® https://platform.openai.com/api-keys
# åˆ›å»ºæ–°å¯†é’¥
export OPENAI_API_KEY="sk-..."
```

**Google Gemini**:
```bash
# è®¿é—® https://makersuite.google.com/app/apikey
export GOOGLE_API_KEY="..."
```

**Kimi (æœˆä¹‹æš—é¢)**:
```bash
# è®¿é—® https://platform.moonshot.cn/
export MOONSHOT_API_KEY="..."
```

#### 2. å®‰è£…Pythonä¾èµ–
```bash
pip install openai anthropic google-generativeai langchain
```

---

### æ–¹æ¡ˆ2ï¼šæœ¬åœ°éƒ¨ç½²

#### 1. å®‰è£…Ollama
**MacOS/Linux**:
```bash
curl https://ollama.ai/install.sh | sh
```

**Windows**:
```bash
# ä¸‹è½½å®‰è£…å™¨
# https://ollama.ai/download/windows
```

#### 2. ä¸‹è½½æ¨¡å‹
```bash
# ä¸‹è½½Llama 3 (æ¨è)
ollama pull llama3

# æˆ–è€…ä¸‹è½½Mistral
ollama pull mistral

# æˆ–è€…ä¸­æ–‡ä¼˜åŒ–çš„Qwen
ollama pull qwen
```

#### 3. æµ‹è¯•æ¨¡å‹
```bash
ollama run llama3
```

---

## âœï¸ åˆ›ä½œç¬¬ä¸€ä¸ªæ•…äº‹

### ä½¿ç”¨Python + OpenAI

#### æ–¹å¼1ï¼šç®€å•è„šæœ¬
```python
import openai
import os

# è®¾ç½®APIå¯†é’¥
openai.api_key = os.getenv("OPENAI_API_KEY")

# å®šä¹‰æç¤ºè¯
prompt = """
è¯·å†™ä¸€ä¸ªç§‘å¹»çŸ­ç¯‡å°è¯´çš„å¼€å¤´ï¼ˆçº¦500å­—ï¼‰ã€‚

è®¾å®šï¼š
- æ—¶é—´ï¼š2157å¹´
- åœ°ç‚¹ï¼šç«æ˜Ÿæ®–æ°‘åœ°
- ä¸»è§’ï¼šå¹´è½»çš„å·¥ç¨‹å¸ˆææ˜
- å†²çªï¼šå‘ç°äº†æœªçŸ¥çš„åœ°ä¸‹ç»“æ„

è¦æ±‚ï¼š
- ç¬¬ä¸‰äººç§°å™è¿°
- æ‚¬ç–‘æ°›å›´
- è¯¦ç»†çš„åœºæ™¯æå†™
"""

# ç”Ÿæˆå†…å®¹
response = openai.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç§‘å¹»å°è¯´ä½œå®¶ã€‚"},
        {"role": "user", "content": prompt}
    ],
    temperature=0.8,
    max_tokens=1000
)

# è¾“å‡ºç»“æœ
story = response.choices[0].message.content
print(story)

# ä¿å­˜åˆ°æ–‡ä»¶
with open("chapter_01.txt", "w", encoding="utf-8") as f:
    f.write(story)
```

#### æ–¹å¼2ï¼šä½¿ç”¨LangChain
```python
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain

# åˆå§‹åŒ–æ¨¡å‹
llm = ChatOpenAI(
    model_name="gpt-4",
    temperature=0.8
)

# åˆ›å»ºæç¤ºè¯æ¨¡æ¿
prompt_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä½{genre}å°è¯´ä½œå®¶ã€‚"),
    ("user", """
    è¯·å†™ä¸€ä¸ª{genre}å°è¯´çš„{part}ï¼ˆçº¦{word_count}å­—ï¼‰ã€‚

    è®¾å®šï¼š
    {setting}

    è¦æ±‚ï¼š
    {requirements}
    """)
])

# åˆ›å»ºé“¾
chain = LLMChain(llm=llm, prompt=prompt_template)

# ç”Ÿæˆå†…å®¹
result = chain.run(
    genre="ç§‘å¹»",
    part="å¼€å¤´",
    word_count=500,
    setting="""
    - æ—¶é—´ï¼š2157å¹´
    - åœ°ç‚¹ï¼šç«æ˜Ÿæ®–æ°‘åœ°
    - ä¸»è§’ï¼šå¹´è½»çš„å·¥ç¨‹å¸ˆææ˜
    """,
    requirements="""
    - ç¬¬ä¸‰äººç§°å™è¿°
    - æ‚¬ç–‘æ°›å›´
    - è¯¦ç»†çš„åœºæ™¯æå†™
    """
)

print(result)
```

---

### ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆOllamaï¼‰

```python
import ollama

# å®šä¹‰æç¤ºè¯
prompt = """
è¯·å†™ä¸€ä¸ªéƒ½å¸‚è¨€æƒ…å°è¯´çš„å¼€å¤´ï¼ˆçº¦500å­—ï¼‰ã€‚

è®¾å®šï¼š
- åœ°ç‚¹ï¼šç°ä»£éƒ½å¸‚
- å¥³ä¸»ï¼šç‹¬ç«‹çš„èŒåœºå¥³æ€§ï¼Œ30å²
- ç”·ä¸»ï¼šç¥ç§˜çš„æ€»è£
- å†²çªï¼šæ„å¤–çš„ç›¸é‡

è¦æ±‚ï¼š
- è½»æ¾å¹½é»˜çš„è¯­æ°”
- ç»†è…»çš„å¿ƒç†æå†™
- å¯¹è¯è‡ªç„¶ç”ŸåŠ¨
"""

# ç”Ÿæˆå†…å®¹
response = ollama.generate(
    model='llama3',
    prompt=prompt,
    options={
        'temperature': 0.8,
        'num_predict': 1000,
    }
)

story = response['response']
print(story)

# ä¿å­˜
with open("romance_chapter_01.txt", "w", encoding="utf-8") as f:
    f.write(story)
```

---

## ğŸ“– å®Œæ•´å°è¯´ç”Ÿæˆæµç¨‹

### é˜¶æ®µ1ï¼šè§„åˆ’ï¼ˆPlanningï¼‰

#### 1.1 å®šä¹‰å°è¯´æ¡†æ¶
```python
novel_outline = {
    "title": "ç«æ˜Ÿä¹‹è°œ",
    "genre": "ç§‘å¹»æ‚¬ç–‘",
    "target_length": "ä¸­ç¯‡ï¼ˆ5-10ä¸‡å­—ï¼‰",
    "main_characters": [
        {
            "name": "ææ˜",
            "role": "ä¸»è§’",
            "description": "25å²å·¥ç¨‹å¸ˆï¼Œå¥½å¥‡å¿ƒå¼ºï¼Œé€»è¾‘æ€ç»´ç¼œå¯†"
        },
        {
            "name": "å¼ è–‡",
            "role": "å¥³ä¸»",
            "description": "åœ°è´¨å­¦å®¶ï¼Œå‹‡æ•¢ç‹¬ç«‹"
        }
    ],
    "plot_points": [
        "å‘ç°åœ°ä¸‹ç»“æ„",
        "æ¢ç´¢ç¥ç§˜è®¾æ–½",
        "é­é‡æœªçŸ¥å±é™©",
        "æ­å¼€çœŸç›¸",
        "åšå‡ºé€‰æ‹©"
    ],
    "chapters": 20
}
```

#### 1.2 ç”Ÿæˆç« èŠ‚å¤§çº²
```python
def generate_chapter_outline(novel_outline):
    prompt = f"""
    æ ¹æ®ä»¥ä¸‹å°è¯´è®¾å®šï¼Œç”Ÿæˆè¯¦ç»†çš„ç« èŠ‚å¤§çº²ï¼š

    æ ‡é¢˜ï¼š{novel_outline['title']}
    ç±»å‹ï¼š{novel_outline['genre']}
    ç« èŠ‚æ•°ï¼š{novel_outline['chapters']}

    ä¸»è¦è§’è‰²ï¼š
    {format_characters(novel_outline['main_characters'])}

    å…³é”®æƒ…èŠ‚ç‚¹ï¼š
    {format_plot_points(novel_outline['plot_points'])}

    è¯·ä¸ºæ¯ä¸€ç« ç”Ÿæˆï¼š
    1. ç« èŠ‚æ ‡é¢˜
    2. ä¸»è¦æƒ…èŠ‚ï¼ˆ2-3å¥è¯ï¼‰
    3. åœºæ™¯å’Œè§’è‰²
    4. é¢„è®¡å­—æ•°
    """

    # è°ƒç”¨AIç”Ÿæˆ
    outline = llm.generate(prompt)
    return outline

# ç”Ÿæˆå¹¶ä¿å­˜å¤§çº²
chapter_outline = generate_chapter_outline(novel_outline)
with open("novel_outline.txt", "w", encoding="utf-8") as f:
    f.write(chapter_outline)
```

---

### é˜¶æ®µ2ï¼šç”Ÿæˆï¼ˆGenerationï¼‰

#### 2.1 é€ç« ç”Ÿæˆ
```python
def generate_chapter(chapter_number, chapter_info, previous_chapters):
    """ç”Ÿæˆå•ä¸ªç« èŠ‚"""

    # æ„å»ºä¸Šä¸‹æ–‡
    context = f"""
    å°è¯´æ ‡é¢˜ï¼š{novel_outline['title']}
    å½“å‰ç« èŠ‚ï¼šç¬¬{chapter_number}ç« 

    ç« èŠ‚ä¿¡æ¯ï¼š
    {chapter_info}

    å‰æƒ…æè¦ï¼š
    {get_summary(previous_chapters)}

    è§’è‰²çŠ¶æ€ï¼š
    {get_character_states(chapter_number)}
    """

    # ç”Ÿæˆç« èŠ‚å†…å®¹
    prompt = f"""
    {context}

    è¯·å†™ç¬¬{chapter_number}ç« çš„å†…å®¹ï¼ˆçº¦3000-5000å­—ï¼‰ã€‚

    è¦æ±‚ï¼š
    1. ä¿æŒè§’è‰²æ€§æ ¼ä¸€è‡´
    2. æƒ…èŠ‚è‡ªç„¶æ¨è¿›
    3. åœºæ™¯æå†™ç»†è…»
    4. å¯¹è¯çœŸå®ç”ŸåŠ¨
    5. ä¿æŒæ‚¬ç–‘æ°›å›´
    """

    chapter_content = llm.generate(
        prompt,
        temperature=0.8,
        max_tokens=3000
    )

    return chapter_content

# ç”Ÿæˆæ‰€æœ‰ç« èŠ‚
chapters = []
for i in range(1, novel_outline['chapters'] + 1):
    print(f"æ­£åœ¨ç”Ÿæˆç¬¬{i}ç« ...")

    chapter_info = get_chapter_info(chapter_outline, i)
    chapter = generate_chapter(i, chapter_info, chapters)

    chapters.append(chapter)

    # ä¿å­˜æ¯ç« 
    with open(f"chapter_{i:02d}.txt", "w", encoding="utf-8") as f:
        f.write(f"# ç¬¬{i}ç« \n\n")
        f.write(chapter)

    print(f"ç¬¬{i}ç« ç”Ÿæˆå®Œæˆï¼")
```

#### 2.2 ä¿æŒè¿è´¯æ€§
```python
def get_summary(previous_chapters, last_n=3):
    """è·å–å‰å‡ ç« çš„æ‘˜è¦"""
    if not previous_chapters:
        return "è¿™æ˜¯ç¬¬ä¸€ç« ã€‚"

    recent_chapters = previous_chapters[-last_n:]

    prompt = f"""
    è¯·ç”¨2-3å¥è¯æ€»ç»“ä»¥ä¸‹å†…å®¹çš„å…³é”®æƒ…èŠ‚ï¼š

    {' '.join(recent_chapters)}
    """

    summary = llm.generate(prompt, max_tokens=200)
    return summary
```

---

### é˜¶æ®µ3ï¼šæ¶¦è‰²ï¼ˆRefinementï¼‰

#### 3.1 å†…å®¹æ£€æŸ¥
```python
def check_consistency(chapters):
    """æ£€æŸ¥æƒ…èŠ‚ä¸€è‡´æ€§"""
    prompt = f"""
    è¯·æ£€æŸ¥ä»¥ä¸‹å°è¯´å†…å®¹çš„ä¸€è‡´æ€§é—®é¢˜ï¼š

    {combine_chapters(chapters)}

    è¯·æŒ‡å‡ºï¼š
    1. æ—¶é—´çº¿çŸ›ç›¾
    2. è§’è‰²æ€§æ ¼ä¸ä¸€è‡´
    3. æƒ…èŠ‚é€»è¾‘é—®é¢˜
    4. å‰åçŸ›ç›¾ä¹‹å¤„
    """

    issues = llm.generate(prompt)
    return issues

# è¿è¡Œæ£€æŸ¥
issues = check_consistency(chapters)
print(issues)
```

#### 3.2 æ–‡å­—æ¶¦è‰²
```python
def polish_text(chapter_text):
    """æ¶¦è‰²å•ç« å†…å®¹"""
    prompt = f"""
    è¯·æ¶¦è‰²ä»¥ä¸‹æ–‡å­—ï¼Œæå‡è¡¨è¾¾è´¨é‡ï¼š

    {chapter_text}

    è¦æ±‚ï¼š
    1. ä¿æŒåŸæ„å’Œé£æ ¼
    2. ä¼˜åŒ–è¯­è¨€è¡¨è¾¾
    3. å¢å¼ºæƒ…æ„Ÿæ¸²æŸ“
    4. æ”¹è¿›å¯¹è¯çœŸå®æ€§
    5. åˆ é™¤å†—ä½™å†…å®¹
    """

    polished = llm.generate(prompt, temperature=0.7)
    return polished

# æ¶¦è‰²æ‰€æœ‰ç« èŠ‚
polished_chapters = []
for i, chapter in enumerate(chapters):
    print(f"æ­£åœ¨æ¶¦è‰²ç¬¬{i+1}ç« ...")
    polished = polish_text(chapter)
    polished_chapters.append(polished)

    # ä¿å­˜æ¶¦è‰²ç‰ˆæœ¬
    with open(f"chapter_{i+1:02d}_polished.txt", "w", encoding="utf-8") as f:
        f.write(polished)
```

---

### é˜¶æ®µ4ï¼šæ•´åˆï¼ˆAssemblyï¼‰

#### 4.1 åˆå¹¶æˆå®Œæ•´å°è¯´
```python
def assemble_novel(title, chapters):
    """åˆå¹¶æ‰€æœ‰ç« èŠ‚"""
    novel = f"# {title}\n\n"
    novel += "---\n\n"

    for i, chapter in enumerate(chapters, 1):
        novel += f"## ç¬¬{i}ç« \n\n"
        novel += chapter
        novel += "\n\n---\n\n"

    return novel

# ç”Ÿæˆå®Œæ•´å°è¯´
full_novel = assemble_novel(novel_outline['title'], polished_chapters)

# ä¿å­˜
with open("full_novel.txt", "w", encoding="utf-8") as f:
    f.write(full_novel)

print(f"å®Œæ•´å°è¯´å·²ç”Ÿæˆï¼æ€»å­—æ•°ï¼š{len(full_novel)}")
```

---

## ğŸ¯ æç¤ºè¯æŠ€å·§

### åŸºç¡€æ¨¡æ¿
```
è§’è‰²ï¼šä½ æ˜¯[è§’è‰²æè¿°]
ä»»åŠ¡ï¼š[å…·ä½“ä»»åŠ¡]
èƒŒæ™¯ï¼š[ç›¸å…³èƒŒæ™¯ä¿¡æ¯]
è¦æ±‚ï¼š[å…·ä½“è¦æ±‚æ¸…å•]
æ ¼å¼ï¼š[è¾“å‡ºæ ¼å¼]
```

### é«˜è´¨é‡æç¤ºè¯ç¤ºä¾‹

#### åœºæ™¯æå†™
```
è¯·æå†™ä¸€ä¸ªé›¨å¤œçš„éƒ½å¸‚è¡—é“åœºæ™¯ï¼ˆçº¦200å­—ï¼‰ã€‚

æ—¶é—´ï¼šæ·±å¤œ11ç‚¹
åœ°ç‚¹ï¼šå¸‚ä¸­å¿ƒå•†ä¸šè¡—
å¤©æ°”ï¼šæš´é›¨
æ°›å›´ï¼šå­¤ç‹¬ã€å‹æŠ‘
è§†è§’ï¼šç¬¬ä¸‰äººç§°ï¼Œè·Ÿéšä¸»è§’

è¦æ±‚ï¼š
1. è°ƒåŠ¨å¤šç§æ„Ÿå®˜ï¼ˆè§†è§‰ã€å¬è§‰ã€è§¦è§‰ï¼‰
2. ä½¿ç”¨æ¯”å–»å’Œæ„è±¡
3. è¥é€ æƒ…ç»ªæ°›å›´
4. é¿å…é™ˆè¯æ»¥è°ƒ
5. è¯­è¨€ç®€æ´æœ‰åŠ›
```

#### è§’è‰²å¯¹è¯
```
è¯·å†™ä¸€æ®µä¸¤äººçš„å¯¹è¯ï¼ˆçº¦300å­—ï¼‰ã€‚

åœºæ™¯ï¼šå’–å•¡å…
è§’è‰²Aï¼šææ˜ï¼Œ25å²ï¼Œç¨‹åºå‘˜ï¼Œå†…å‘ç†æ€§
è§’è‰²Bï¼šå¼ è–‡ï¼Œ27å²ï¼Œè®¾è®¡å¸ˆï¼Œå¤–å‘æ„Ÿæ€§
å…³ç³»ï¼šåŒäº‹ï¼Œæš—ç”Ÿæƒ…æ„«
å†²çªï¼šè®¨è®ºæ˜¯å¦æ¥å—æ–°çš„å·¥ä½œæœºä¼š

è¦æ±‚ï¼š
1. ç¬¦åˆè§’è‰²æ€§æ ¼
2. å¯¹è¯è‡ªç„¶ç”ŸåŠ¨
3. æœ‰æ½œå°è¯å’Œå¼ åŠ›
4. æ¨è¿›æƒ…èŠ‚å‘å±•
5. é€‚å½“åŠ å…¥åŠ¨ä½œå’Œç¥æ€æå†™
```

#### æƒ…èŠ‚è½¬æŠ˜
```
å½“å‰æƒ…èŠ‚ï¼šä¸»è§’ä»¥ä¸ºæ‰¾åˆ°äº†çœŸç›¸
è½¬æŠ˜ï¼šå‘ç°ä¸€åˆ‡éƒ½æ˜¯å‡è±¡
è¦æ±‚ï¼š
1. åœ¨3ä¸ªæ®µè½å†…å®Œæˆè½¬æŠ˜
2. ç¬¬ä¸€æ®µé“ºå«æš—ç¤º
3. ç¬¬äºŒæ®µæ­ç¤ºè½¬æŠ˜
4. ç¬¬ä¸‰æ®µæƒ…æ„Ÿå†²å‡»
5. ä¿æŒæ‚¬å¿µæ„Ÿ
```

---

## ğŸ› ï¸ å®ç”¨å·¥å…·è„šæœ¬

### å­—æ•°ç»Ÿè®¡
```python
def count_words(text):
    """ç»Ÿè®¡ä¸­è‹±æ–‡å­—æ•°"""
    import re

    # ä¸­æ–‡å­—ç¬¦
    chinese = len(re.findall(r'[\u4e00-\u9fff]', text))
    # è‹±æ–‡å•è¯
    english = len(re.findall(r'\b[a-zA-Z]+\b', text))

    return {
        'chinese': chinese,
        'english': english,
        'total': chinese + english
    }

# ä½¿ç”¨
stats = count_words(full_novel)
print(f"ä¸­æ–‡å­—ç¬¦ï¼š{stats['chinese']}")
print(f"è‹±æ–‡å•è¯ï¼š{stats['english']}")
print(f"æ€»å­—æ•°ï¼š{stats['total']}")
```

### å…³é”®è¯æå–
```python
def extract_keywords(text, top_n=20):
    """æå–æ–‡æœ¬å…³é”®è¯"""
    # å¯ä»¥ä½¿ç”¨ jieba, NLTK ç­‰
    import jieba.analyse

    keywords = jieba.analyse.extract_tags(
        text,
        topK=top_n,
        withWeight=True
    )

    return keywords

# ä½¿ç”¨
keywords = extract_keywords(full_novel)
for word, weight in keywords:
    print(f"{word}: {weight:.4f}")
```

### å¯¼å‡ºå¤šç§æ ¼å¼
```python
def export_novel(content, title, formats=['txt', 'md', 'docx']):
    """å¯¼å‡ºå¤šç§æ ¼å¼"""

    # TXT
    if 'txt' in formats:
        with open(f"{title}.txt", "w", encoding="utf-8") as f:
            f.write(content)

    # Markdown
    if 'md' in formats:
        with open(f"{title}.md", "w", encoding="utf-8") as f:
            f.write(content)

    # DOCX
    if 'docx' in formats:
        from docx import Document
        doc = Document()
        doc.add_heading(title, 0)
        for para in content.split('\n\n'):
            if para.strip():
                doc.add_paragraph(para)
        doc.save(f"{title}.docx")

    print(f"å·²å¯¼å‡ºæ ¼å¼ï¼š{', '.join(formats)}")

# ä½¿ç”¨
export_novel(full_novel, novel_outline['title'])
```

---

## ğŸ’¡ å¸¸è§é—®é¢˜

### Q1: ç”Ÿæˆçš„å†…å®¹è´¨é‡ä¸é«˜æ€ä¹ˆåŠï¼Ÿ
**A**:
1. ä¼˜åŒ–æç¤ºè¯ï¼Œæä¾›æ›´å¤šç»†èŠ‚
2. ä½¿ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰
3. å¢åŠ temperatureæ¥æå‡åˆ›æ„
4. å¤šæ¬¡ç”Ÿæˆï¼Œé€‰æ‹©æœ€ä½³ç‰ˆæœ¬
5. äººå·¥å®¡æ ¸å’Œä¿®æ”¹

### Q2: å¦‚ä½•ä¿æŒé•¿ç¯‡å°è¯´çš„ä¸€è‡´æ€§ï¼Ÿ
**A**:
1. ç»´æŠ¤è§’è‰²å¡ç‰‡å’Œè®¾å®šæ–‡æ¡£
2. æ¯ç« ç”Ÿæˆæ—¶åŒ…å«å‰æƒ…æ‘˜è¦
3. å®šæœŸè¿è¡Œä¸€è‡´æ€§æ£€æŸ¥
4. ä½¿ç”¨å‘é‡æ•°æ®åº“å­˜å‚¨ä¸Šä¸‹æ–‡
5. äººå·¥å®¡æ ¸å…³é”®æƒ…èŠ‚ç‚¹

### Q3: æˆæœ¬å¤§æ¦‚æ˜¯å¤šå°‘ï¼Ÿ
**A**:
- GPT-4: ~$0.03/1K tokensï¼ˆçº¦$30-50/ä¸‡å­—ï¼‰
- GPT-3.5: ~$0.002/1K tokensï¼ˆçº¦$2-5/ä¸‡å­—ï¼‰
- Gemini: å…è´¹é…é¢ï¼Œä»˜è´¹è¾ƒä¾¿å®œ
- æœ¬åœ°æ¨¡å‹ï¼šå…è´¹ï¼Œä½†éœ€è¦GPU

### Q4: ç”Ÿæˆé€Ÿåº¦å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ
**A**:
1. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼ˆGPT-3.5 vs GPT-4ï¼‰
2. å‡å°‘max_tokens
3. å¹¶è¡Œç”Ÿæˆå¤šä¸ªç« èŠ‚
4. ä½¿ç”¨æœ¬åœ°æ¨¡å‹
5. è€ƒè™‘ä½¿ç”¨GPUåŠ é€Ÿ

### Q5: èƒ½å¦å•†ç”¨AIç”Ÿæˆçš„å°è¯´ï¼Ÿ
**A**:
- å„å¹³å°æ”¿ç­–ä¸åŒï¼Œéœ€è¦æŸ¥çœ‹å…·ä½“æ¡æ¬¾
- OpenAI: ç”¨æˆ·æ‹¥æœ‰ç”Ÿæˆå†…å®¹çš„æƒåˆ©
- å»ºè®®è¿›è¡Œäººå·¥ç¼–è¾‘å’Œä¿®æ”¹
- äº†è§£ç›®æ ‡å¹³å°çš„AIå†…å®¹æ”¿ç­–
- å’¨è¯¢æ³•å¾‹ä¸“ä¸šäººå£«

---

## ğŸ“š è¿›é˜¶å­¦ä¹ 

### æ¨èé˜…è¯»
1. **æç¤ºè¯å·¥ç¨‹**: [PromptingGuide.ai](https://www.promptingguide.ai/)
2. **LangChainæ–‡æ¡£**: [python.langchain.com](https://python.langchain.com/)
3. **OpenAI Cookbook**: [GitHub](https://github.com/openai/openai-cookbook)

### å®è·µé¡¹ç›®
1. ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„çŸ­ç¯‡å°è¯´ï¼ˆ5000å­—ï¼‰
2. åˆ›å»ºè‡ªå·±çš„æç¤ºè¯æ¨¡æ¿åº“
3. å®ç°è‡ªåŠ¨åŒ–çš„ç« èŠ‚ç”Ÿæˆæµç¨‹
4. å¼€å‘ä¸€ä¸ªç®€å•çš„Webç•Œé¢

### åŠ å…¥ç¤¾åŒº
- Reddit: r/AIWriting
- Discord: AI Writing Communities
- GitHub: å‚ä¸å¼€æºé¡¹ç›®

---

## ğŸ‰ å¼€å§‹åˆ›ä½œå§ï¼

ç°åœ¨ä½ å·²ç»æŒæ¡äº†AIå°è¯´å†™ä½œçš„åŸºç¡€çŸ¥è¯†å’Œå·¥å…·ï¼Œå¼€å§‹ä½ çš„åˆ›ä½œä¹‹æ—…å§ï¼

è®°ä½ï¼š
- AIæ˜¯åŠ©æ‰‹ï¼Œä¸æ˜¯æ›¿ä»£å“
- ä¿æŒä½ çš„åˆ›æ„å’Œé£æ ¼
- å¤šå®è·µï¼Œå¤šå°è¯•
- äº«å—åˆ›ä½œçš„è¿‡ç¨‹

ç¥åˆ›ä½œæ„‰å¿«ï¼âœ¨

---

**æœ‰é—®é¢˜ï¼Ÿ**
- æŸ¥çœ‹ [README.md](README.md) äº†è§£æ›´å¤šé¡¹ç›®
- æŸ¥çœ‹ [PROJECT-LIST.md](PROJECT-LIST.md) é€‰æ‹©åˆé€‚çš„å·¥å…·
- å‚è€ƒå„åˆ†ç±»ç›®å½•çš„è¯¦ç»†æ–‡æ¡£
